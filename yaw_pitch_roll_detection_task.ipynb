{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1XOWruxCnMcuyESq-vEvCQlPZTBfMs-52","authorship_tag":"ABX9TyPt5c7+wkAvSyIsust1+E9h"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install -q mediapipe"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QLWxeZaB5kZz","executionInfo":{"status":"ok","timestamp":1726796386381,"user_tz":-180,"elapsed":15426,"user":{"displayName":"Omar Mekkia","userId":"03354026122611285170"}},"outputId":"ebfc1c83-3cb3-4a37-cc4f-9e1d60003108"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.9/35.9 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 4.25.5 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["!wget -O face_landmarker_v2_with_blendshapes.task -q https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task"],"metadata":{"id":"epuzidCT5Xjj"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":1,"metadata":{"id":"6NWaac2k3SKR","executionInfo":{"status":"error","timestamp":1726929698707,"user_tz":-180,"elapsed":546,"user":{"displayName":"Omar Mekkia","userId":"03354026122611285170"}},"colab":{"base_uri":"https://localhost:8080/","height":383},"outputId":"bfb7ca8d-9484-4ef5-981f-57a4c843ae52"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'mediapipe'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-317238a99045>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmediapipe\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmediapipe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msolutions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmediapipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlandmark_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmediapipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpython\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmediapipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mediapipe'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["import mediapipe as mp\n","from mediapipe import solutions\n","from mediapipe.framework.formats import landmark_pb2\n","from mediapipe.tasks import python\n","from mediapipe.tasks.python import vision\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import cv2\n","from google.colab.patches import cv2_imshow\n","import os\n","import pandas as pd\n","\n","\n","\n","def draw_landmarks_on_image(rgb_image, detection_result):\n","\n","    #detect face landmarks for one or more face\n","    face_landmarks_list = detection_result.face_landmarks\n","    annotated_image = np.copy(rgb_image)\n","    for idx in range(len(face_landmarks_list)):\n","        face_landmarks = face_landmarks_list[idx]\n","\n","    #normalize face landmarks between 0 and 1\n","    face_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n","    face_landmarks_proto.landmark.extend([\n","      landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in face_landmarks])\n","\n","    #draw face landmarks and making connections between them\n","    #tesselation style is making the newtork of triangles on the face\n","    #contour style highlights the lips, eyes, eyebrows\n","    #irises style highlights the irises of the eyes\n","\n","    solutions.drawing_utils.draw_landmarks(\n","        image=annotated_image,\n","        landmark_list=face_landmarks_proto,\n","        connections=mp.solutions.face_mesh.FACEMESH_TESSELATION,\n","        landmark_drawing_spec=None,\n","        connection_drawing_spec=mp.solutions.drawing_styles\n","        .get_default_face_mesh_tesselation_style())\n","    solutions.drawing_utils.draw_landmarks(\n","        image=annotated_image,\n","        landmark_list=face_landmarks_proto,\n","        connections=mp.solutions.face_mesh.FACEMESH_CONTOURS,\n","        landmark_drawing_spec=None,\n","        connection_drawing_spec=mp.solutions.drawing_styles\n","        .get_default_face_mesh_contours_style())\n","    solutions.drawing_utils.draw_landmarks(\n","        image=annotated_image,\n","        landmark_list=face_landmarks_proto,\n","        connections=mp.solutions.face_mesh.FACEMESH_IRISES,\n","          landmark_drawing_spec=None,\n","          connection_drawing_spec=mp.solutions.drawing_styles\n","          .get_default_face_mesh_iris_connections_style())\n","\n","    return annotated_image , face_landmarks_proto\n","\n","\n","\n","def getYPR(detection_result):\n","    R = detection_result.facial_transformation_matrixes[0][:3,:3]\n","    if abs(R[2, 0]) != 1:\n","\n","          pitch = -np.arcsin(R[2, 0])  # theta (pitch)\n","          yaw = np.arctan2(R[1, 0], R[0, 0])  # psi (yaw)\n","          roll = np.arctan2(R[2, 1], R[2, 2])  # phi (roll)\n","    else:\n","        # Gimbal lock case\n","        if R[2, 0] == -1:\n","          pitch = np.pi / 2\n","          yaw = np.arctan2(-R[0, 1], R[0, 2])\n","          roll = 0\n","        else:\n","          pitch = -np.pi / 2\n","          yaw = np.arctan2(R[0, 1], R[0, 2])\n","          roll = 0\n","\n","    pitch = pitch*180\n","    yaw = yaw*180\n","    roll = roll*180\n","    return yaw, pitch, roll\n","\n","def drawYPRonIMG(face_landmarks_proto,yaw,pitch,roll):\n","    landmarks_data = [(lm.x, lm.y, lm.z) for lm in face_landmarks_proto.landmark]\n","    landmarks_array = np.array(landmarks_data)\n","\n","    left_eyebrow_landmarks = [landmarks_array[i] for i in range(33, 133)]\n","    right_eyebrow_landmarks = [landmarks_array[i] for i in range(362, 464)]\n","\n","    left_eyebrow_avg = np.mean(left_eyebrow_landmarks, axis=0)\n","    right_eyebrow_avg = np.mean(right_eyebrow_landmarks, axis=0)\n","    avg_position = ((left_eyebrow_avg[0] + right_eyebrow_avg[0]) / 2, (left_eyebrow_avg[1] + right_eyebrow_avg[1]) / 2)\n","    w, h, _ = img.shape\n","    avg_position = (int(avg_position[0] * w), int(avg_position[1] * h))\n","\n","\n","    center = avg_position\n","    length = 100\n","    line_thickness = 3\n","\n","\n","    yaw_end = (int(center[0] + length * np.cos(np.radians(yaw))),\n","               int(center[1] - length * np.sin(np.radians(yaw))))\n","\n","    pitch_end = (int(center[0] + length * np.sin(np.radians(pitch))),\n","                 int(center[1] - length * np.cos(np.radians(pitch))))\n","\n","    roll_end = (int(center[0] + length * np.cos(np.radians(roll))),\n","                int(center[1] - length * np.sin(np.radians(roll))))\n","    cv2.arrowedLine(img, center, yaw_end, (255,0,0), line_thickness)\n","    cv2.arrowedLine(img, center, pitch_end, (0,255,0), line_thickness)\n","    cv2.arrowedLine(img, center, roll_end, (0,0,255), line_thickness)\n","\n","    cv2_imshow(img)\n","\n","\n","\n","\n","base_options = python.BaseOptions(model_asset_path='face_landmarker_v2_with_blendshapes.task')\n","options = vision.FaceLandmarkerOptions(base_options=base_options,\n","                                       output_face_blendshapes=True,\n","                                       output_facial_transformation_matrixes=True,\n","                                       num_faces=1)\n","detector = vision.FaceLandmarker.create_from_options(options)\n","noface =0\n","\n","posedata = pd.DataFrame(columns=['url', 'yaw','pitch','roll'])\n","DirPath = \"/content/drive/MyDrive/AFLW2000\"\n","Files = os.listdir(DirPath)\n","for File in Files:\n","    img_path = os.path.join(DirPath, File)\n","    img = mp.Image.create_from_file(img_path)\n","    detection_result = detector.detect(img)\n","    if detection_result.face_landmarks:\n","       yaw, pitch, roll = getYPR(detection_result)\n","       posedata.loc[len(posedata.index)] = [img_path, yaw, pitch, roll]\n","\n","\n","posedata.to_csv('/content/drive/MyDrive/data.csv')\n","\n","\n"]}]}